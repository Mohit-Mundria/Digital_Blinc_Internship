{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e67b91c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0840ae34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a little throwback with my favourite person  w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>glam on  yesterday for kcon makeup using  in f...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>democracy plaza in the wake of a stunning outc...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>then amp now vilo  walt disney magic kingdom</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>who never  a galaxy far far away</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Label\n",
       "0  a little throwback with my favourite person  w...      0\n",
       "1  glam on  yesterday for kcon makeup using  in f...      7\n",
       "2  democracy plaza in the wake of a stunning outc...     11\n",
       "3       then amp now vilo  walt disney magic kingdom      0\n",
       "4                   who never  a galaxy far far away      2"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=pd.read_csv(\"D:\\End to end project\\Digital Blink\\Emoji Predictor\\emoji_cleaned.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "18da367f",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_data=open(r\"D:\\End to end project\\Digital Blink\\Emoji Predictor\\us_mapping.txt\",'r')\n",
    "lines = map_data.readlines()  # Read lines from file\n",
    "map_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "efa4ad22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>emoji</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>â¤ï¸</td>\n",
       "      <td>Red heart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ğŸ˜</td>\n",
       "      <td>Smiling face with hearteyes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ğŸ˜‚</td>\n",
       "      <td>Face with tears of joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ğŸ’•</td>\n",
       "      <td>Two hearts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ğŸ”¥</td>\n",
       "      <td>Fire</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Score emoji                          name\n",
       "0     0    â¤ï¸                     Red heart\n",
       "1     1     ğŸ˜   Smiling face with hearteyes\n",
       "2     2     ğŸ˜‚        Face with tears of joy\n",
       "3     3     ğŸ’•                    Two hearts\n",
       "4     4     ğŸ”¥                          Fire"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = [line.strip().split('\\t') for line in lines]\n",
    "dataset_map = pd.DataFrame(records, columns=[\"Score\", \"emoji\", \"name\"])\n",
    "\n",
    "dataset_map.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "57b120ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': ['â¤ï¸', ' Red heart'],\n",
       " '1': ['ğŸ˜', ' Smiling face with hearteyes'],\n",
       " '2': ['ğŸ˜‚', ' Face with tears of joy'],\n",
       " '3': ['ğŸ’•', ' Two hearts'],\n",
       " '4': ['ğŸ”¥', ' Fire'],\n",
       " '5': ['ğŸ˜Š', ' Smiling face with smiling eyes'],\n",
       " '6': ['ğŸ˜', ' Smiling face with sunglasses'],\n",
       " '7': ['âœ¨', ' Sparkles'],\n",
       " '8': ['ğŸ’™', ' Blue heart'],\n",
       " '9': ['ğŸ˜˜', ' Face blowing a kiss'],\n",
       " '10': ['ğŸ“·', ' Camera'],\n",
       " '11': ['ğŸ‡ºğŸ‡¸', ' United States'],\n",
       " '12': ['â˜€ï¸', ' Sun'],\n",
       " '13': ['ğŸ’œ', ' Purple heart'],\n",
       " '14': ['ğŸ˜‰', ' Winking face'],\n",
       " '15': ['ğŸ’¯', ' Hundred points'],\n",
       " '16': ['ğŸ˜', ' Beaming face with smiling eyes'],\n",
       " '17': ['ğŸ„', 'Christmas tree'],\n",
       " '18': ['ğŸ“¸', 'Camera with flash'],\n",
       " '19': ['ğŸ˜œ', 'Winking face with tongue']}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_dict=dataset_map.set_index('Score').T.to_dict('list')\n",
    "map_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8a5c934f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0d8be4eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a little throwback with my favourite person  w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>glam on  yesterday for kcon makeup using  in f...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>democracy plaza in the wake of a stunning outc...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>then amp now vilo  walt disney magic kingdom</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>who never  a galaxy far far away</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>my ootd love this chain so much and our new ri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>met santa and olaf  the north pole today  nort...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>new york by night strideby herelocationnyc see...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>kisses for the birthday girl  helzberg diamonds</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>dinner with this priceless viewthank you s ann...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49999 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Tweet  Label\n",
       "0      a little throwback with my favourite person  w...      0\n",
       "1      glam on  yesterday for kcon makeup using  in f...      7\n",
       "2      democracy plaza in the wake of a stunning outc...     11\n",
       "3           then amp now vilo  walt disney magic kingdom      0\n",
       "4                       who never  a galaxy far far away      2\n",
       "...                                                  ...    ...\n",
       "49995  my ootd love this chain so much and our new ri...      1\n",
       "49996  met santa and olaf  the north pole today  nort...      0\n",
       "49997  new york by night strideby herelocationnyc see...     11\n",
       "49998    kisses for the birthday girl  helzberg diamonds      0\n",
       "49999  dinner with this priceless viewthank you s ann...      9\n",
       "\n",
       "[49999 rows x 2 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.drop(index=16070)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d15dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "dataset['Tweet'] = dataset['Tweet'].astype(str)\n",
    "\n",
    "\n",
    "dataset['Tweet'] = dataset['Tweet'].apply(\n",
    "    lambda x: tokenizer.tokenize(x)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "97a042e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[a, little, throw, ##back, with, my, favourite...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[g, ##lam, on, yesterday, for, kc, ##on, makeu...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[democracy, plaza, in, the, wake, of, a, stunn...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[then, amp, now, vi, ##lo, walt, disney, magic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[who, never, a, galaxy, far, far, away]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>[my, o, ##ot, ##d, love, this, chain, so, much...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>[met, santa, and, olaf, the, north, pole, toda...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>[new, york, by, night, stride, ##by, here, ##l...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>[kisses, for, the, birthday, girl, he, ##lz, #...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>[dinner, with, this, price, ##less, view, ##th...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Tweet  Label\n",
       "0      [a, little, throw, ##back, with, my, favourite...      0\n",
       "1      [g, ##lam, on, yesterday, for, kc, ##on, makeu...      7\n",
       "2      [democracy, plaza, in, the, wake, of, a, stunn...     11\n",
       "3      [then, amp, now, vi, ##lo, walt, disney, magic...      0\n",
       "4                [who, never, a, galaxy, far, far, away]      2\n",
       "...                                                  ...    ...\n",
       "49995  [my, o, ##ot, ##d, love, this, chain, so, much...      1\n",
       "49996  [met, santa, and, olaf, the, north, pole, toda...      0\n",
       "49997  [new, york, by, night, stride, ##by, here, ##l...     11\n",
       "49998  [kisses, for, the, birthday, girl, he, ##lz, #...      0\n",
       "49999  [dinner, with, this, price, ##less, view, ##th...      9\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2c9a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Train Word2Vec model\n",
    "w2v_model = Word2Vec(\n",
    "    sentences=dataset['Tweet'],            # list of tokenized sentences\n",
    "    vector_size=100,      # size of embedding vector\n",
    "    window=5,             # context window\n",
    "    min_count=1,          \n",
    "    workers=4,            \n",
    "    sg=1                  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c4423827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[a, little, throw, ##back, with, my, favourite...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[g, ##lam, on, yesterday, for, kc, ##on, makeu...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[democracy, plaza, in, the, wake, of, a, stunn...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[then, amp, now, vi, ##lo, walt, disney, magic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[who, never, a, galaxy, far, far, away]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>[my, o, ##ot, ##d, love, this, chain, so, much...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>[met, santa, and, olaf, the, north, pole, toda...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>[new, york, by, night, stride, ##by, here, ##l...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>[kisses, for, the, birthday, girl, he, ##lz, #...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>[dinner, with, this, price, ##less, view, ##th...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Tweet  Label\n",
       "0      [a, little, throw, ##back, with, my, favourite...      0\n",
       "1      [g, ##lam, on, yesterday, for, kc, ##on, makeu...      7\n",
       "2      [democracy, plaza, in, the, wake, of, a, stunn...     11\n",
       "3      [then, amp, now, vi, ##lo, walt, disney, magic...      0\n",
       "4                [who, never, a, galaxy, far, far, away]      2\n",
       "...                                                  ...    ...\n",
       "49995  [my, o, ##ot, ##d, love, this, chain, so, much...      1\n",
       "49996  [met, santa, and, olaf, the, north, pole, toda...      0\n",
       "49997  [new, york, by, night, stride, ##by, here, ##l...     11\n",
       "49998  [kisses, for, the, birthday, girl, he, ##lz, #...      0\n",
       "49999  [dinner, with, this, price, ##less, view, ##th...      9\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e2f029",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "w2v_model = Word2Vec(sentences=dataset['Tweet'], vector_size=100, min_count=1)\n",
    "\n",
    "def sentence_embedding(tokens):\n",
    "    vecs = [w2v_model.wv[word] for word in tokens if word in w2v_model.wv]\n",
    "    if len(vecs) == 0:\n",
    "        return np.zeros(w2v_model.vector_size)\n",
    "    return np.mean(vecs, axis=0)\n",
    "dataset['sentence_vector'] = dataset['Tweet'].apply(sentence_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a2f8adf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Label</th>\n",
       "      <th>sentence_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[a, little, throw, ##back, with, my, favourite...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.05411576, 0.51391613, -0.34405714, -0.0724...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[g, ##lam, on, yesterday, for, kc, ##on, makeu...</td>\n",
       "      <td>7</td>\n",
       "      <td>[-0.15656765, 0.18488812, 0.09924544, -0.09187...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[democracy, plaza, in, the, wake, of, a, stunn...</td>\n",
       "      <td>11</td>\n",
       "      <td>[-0.20746422, 0.13515742, -0.11181886, -0.1534...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[then, amp, now, vi, ##lo, walt, disney, magic...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.7232284, 0.22566159, -0.0238593, 0.4682785...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[who, never, a, galaxy, far, far, away]</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.11715334, 0.5868083, -0.11975988, -0.31505...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>[my, o, ##ot, ##d, love, this, chain, so, much...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.057419136, 0.5462586, 0.050390612, -0.02191...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>[met, santa, and, olaf, the, north, pole, toda...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.050597295, 0.24881114, -0.19427519, -0.030...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>[new, york, by, night, stride, ##by, here, ##l...</td>\n",
       "      <td>11</td>\n",
       "      <td>[-0.0051931962, 0.2199232, -0.04641551, 0.2292...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>[kisses, for, the, birthday, girl, he, ##lz, #...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.054742143, 0.15744086, 0.18865676, -0.0402...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>[dinner, with, this, price, ##less, view, ##th...</td>\n",
       "      <td>9</td>\n",
       "      <td>[0.0160627, 0.26198086, -0.0031612823, 0.04056...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Tweet  Label  \\\n",
       "0      [a, little, throw, ##back, with, my, favourite...      0   \n",
       "1      [g, ##lam, on, yesterday, for, kc, ##on, makeu...      7   \n",
       "2      [democracy, plaza, in, the, wake, of, a, stunn...     11   \n",
       "3      [then, amp, now, vi, ##lo, walt, disney, magic...      0   \n",
       "4                [who, never, a, galaxy, far, far, away]      2   \n",
       "...                                                  ...    ...   \n",
       "49995  [my, o, ##ot, ##d, love, this, chain, so, much...      1   \n",
       "49996  [met, santa, and, olaf, the, north, pole, toda...      0   \n",
       "49997  [new, york, by, night, stride, ##by, here, ##l...     11   \n",
       "49998  [kisses, for, the, birthday, girl, he, ##lz, #...      0   \n",
       "49999  [dinner, with, this, price, ##less, view, ##th...      9   \n",
       "\n",
       "                                         sentence_vector  \n",
       "0      [-0.05411576, 0.51391613, -0.34405714, -0.0724...  \n",
       "1      [-0.15656765, 0.18488812, 0.09924544, -0.09187...  \n",
       "2      [-0.20746422, 0.13515742, -0.11181886, -0.1534...  \n",
       "3      [-0.7232284, 0.22566159, -0.0238593, 0.4682785...  \n",
       "4      [-0.11715334, 0.5868083, -0.11975988, -0.31505...  \n",
       "...                                                  ...  \n",
       "49995  [0.057419136, 0.5462586, 0.050390612, -0.02191...  \n",
       "49996  [-0.050597295, 0.24881114, -0.19427519, -0.030...  \n",
       "49997  [-0.0051931962, 0.2199232, -0.04641551, 0.2292...  \n",
       "49998  [-0.054742143, 0.15744086, 0.18865676, -0.0402...  \n",
       "49999  [0.0160627, 0.26198086, -0.0031612823, 0.04056...  \n",
       "\n",
       "[50000 rows x 3 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a06c82e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=dataset['sentence_vector']\n",
    "y=dataset['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a0de6a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(np.vstack(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "18a0df0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=42,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4fea7780",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.vstack(x_train)\n",
    "x_test = np.vstack(x_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448bd3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\miniconda3\\envs\\venv2\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\ACER\\miniconda3\\envs\\venv2\\lib\\site-packages\\keras\\src\\ops\\nn.py:944: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n",
      "c:\\Users\\ACER\\miniconda3\\envs\\venv2\\lib\\site-packages\\keras\\src\\losses\\losses.py:33: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
      "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.1052 - loss: 0.0000e+00 - val_accuracy: 0.1035 - val_loss: 0.0000e+00\n",
      "Epoch 2/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1057 - loss: 0.0000e+00 - val_accuracy: 0.1035 - val_loss: 0.0000e+00\n",
      "Epoch 3/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1054 - loss: 0.0000e+00 - val_accuracy: 0.1035 - val_loss: 0.0000e+00\n",
      "Epoch 4/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1066 - loss: 0.0000e+00 - val_accuracy: 0.1035 - val_loss: 0.0000e+00\n",
      "Epoch 5/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.1073 - loss: 0.0000e+00 - val_accuracy: 0.1035 - val_loss: 0.0000e+00\n",
      "Epoch 6/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.1072 - loss: 0.0000e+00 - val_accuracy: 0.1035 - val_loss: 0.0000e+00\n",
      "Epoch 7/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.1062 - loss: 0.0000e+00 - val_accuracy: 0.1035 - val_loss: 0.0000e+00\n",
      "Epoch 8/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.1022 - loss: 0.0000e+00 - val_accuracy: 0.1035 - val_loss: 0.0000e+00\n",
      "Epoch 9/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1055 - loss: 0.0000e+00 - val_accuracy: 0.1035 - val_loss: 0.0000e+00\n",
      "Epoch 10/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1050 - loss: 0.0000e+00 - val_accuracy: 0.1035 - val_loss: 0.0000e+00\n",
      "Epoch 11/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1066 - loss: 0.0000e+00 - val_accuracy: 0.1035 - val_loss: 0.0000e+00\n",
      "Epoch 12/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1050 - loss: 0.0000e+00 - val_accuracy: 0.1035 - val_loss: 0.0000e+00\n",
      "Epoch 13/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1031 - loss: 0.0000e+00 - val_accuracy: 0.1035 - val_loss: 0.0000e+00\n",
      "Epoch 14/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1045 - loss: 0.0000e+00 - val_accuracy: 0.1035 - val_loss: 0.0000e+00\n",
      "Epoch 15/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1070 - loss: 0.0000e+00 - val_accuracy: 0.1035 - val_loss: 0.0000e+00\n",
      "Epoch 16/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1066 - loss: 0.0000e+00 - val_accuracy: 0.1035 - val_loss: 0.0000e+00\n",
      "Epoch 17/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1060 - loss: 0.0000e+00 - val_accuracy: 0.1035 - val_loss: 0.0000e+00\n",
      "Epoch 18/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1049 - loss: 0.0000e+00 - val_accuracy: 0.1035 - val_loss: 0.0000e+00\n",
      "Epoch 19/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1048 - loss: 0.0000e+00 - val_accuracy: 0.1035 - val_loss: 0.0000e+00\n",
      "Epoch 20/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1048 - loss: 0.0000e+00 - val_accuracy: 0.1035 - val_loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2aa16ded550>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout \n",
    "\n",
    "model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(100,)),\n",
    "    Dropout(0.3),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='softmax')  \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=20,batch_size=128, validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "73a9a7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0991 - loss: 0.0000e+00\n",
      "Test Accuracy: 0.1035\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Accuracy: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b1da89f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.80      0.40      2153\n",
      "           1       0.20      0.08      0.11      1035\n",
      "           2       0.29      0.51      0.37      1048\n",
      "           3       0.27      0.01      0.01       574\n",
      "           4       0.27      0.23      0.25       520\n",
      "           5       0.27      0.02      0.04       486\n",
      "           6       0.11      0.01      0.02       390\n",
      "           7       0.21      0.02      0.04       376\n",
      "           8       0.33      0.01      0.01       382\n",
      "           9       0.20      0.01      0.01       341\n",
      "          10       0.15      0.05      0.07       273\n",
      "          11       0.29      0.15      0.20       329\n",
      "          12       0.26      0.16      0.20       286\n",
      "          13       0.00      0.00      0.00       270\n",
      "          14       0.00      0.00      0.00       272\n",
      "          15       0.14      0.01      0.02       251\n",
      "          16       0.00      0.00      0.00       246\n",
      "          17       0.75      0.57      0.65       280\n",
      "          18       0.17      0.02      0.04       245\n",
      "          19       0.00      0.00      0.00       243\n",
      "\n",
      "    accuracy                           0.28     10000\n",
      "   macro avg       0.21      0.13      0.12     10000\n",
      "weighted avg       0.23      0.28      0.19     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\miniconda3\\envs\\venv2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ACER\\miniconda3\\envs\\venv2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ACER\\miniconda3\\envs\\venv2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a625b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.07      0.12      2153\n",
      "           1       0.15      0.02      0.03      1035\n",
      "           2       0.26      0.39      0.31      1048\n",
      "           3       0.13      0.15      0.14       574\n",
      "           4       0.16      0.12      0.13       520\n",
      "           5       0.09      0.05      0.06       486\n",
      "           6       0.07      0.01      0.01       390\n",
      "           7       0.13      0.06      0.08       376\n",
      "           8       0.07      0.02      0.03       382\n",
      "           9       0.08      0.13      0.10       341\n",
      "          10       0.04      0.44      0.08       273\n",
      "          11       0.12      0.22      0.15       329\n",
      "          12       0.13      0.27      0.17       286\n",
      "          13       0.09      0.01      0.01       270\n",
      "          14       0.05      0.23      0.08       272\n",
      "          15       0.00      0.00      0.00       251\n",
      "          16       0.04      0.02      0.03       246\n",
      "          17       0.66      0.56      0.61       280\n",
      "          18       0.00      0.00      0.00       245\n",
      "          19       0.05      0.00      0.01       243\n",
      "\n",
      "    accuracy                           0.13     10000\n",
      "   macro avg       0.14      0.14      0.11     10000\n",
      "weighted avg       0.20      0.13      0.12     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "gnb=GaussianNB()\n",
    "gnb.fit(x_train,y_train)\n",
    "\n",
    "\n",
    "y_pred=gnb.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843b3377",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='linear', C=1, decision_function_shape='ovr')  \n",
    "svm_model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = svm_model.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaba6ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
